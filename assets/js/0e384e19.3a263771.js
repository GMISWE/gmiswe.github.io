"use strict";(self.webpackChunkdocument_site=self.webpackChunkdocument_site||[]).push([[3976],{7879:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"intro","title":"What We Do","description":"Get Started with GMI AI Cloud","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Welcome!","permalink":"/"},"next":{"title":"Cluster Engine","permalink":"/cluster-engine/"}}');var i=n(4848),o=n(8453);const a={sidebar_position:2},s="What We Do",c={},l=[{value:"Get Started with GMI AI Cloud",id:"get-started-with-gmi-ai-cloud",level:2},{value:"Hassle Free Deployment",id:"hassle-free-deployment",level:2},{value:"Cloud-native Orchestration",id:"cloud-native-orchestration",level:2},{value:"Bare-metal Storage/Networking",id:"bare-metal-storagenetworking",level:2},{value:"Flexible GPU Compute",id:"flexible-gpu-compute",level:2},{value:"Robust Security",id:"robust-security",level:2},{value:"Unprecedented Hardware Access",id:"unprecedented-hardware-access",level:2}];function d(e){const t={h1:"h1",h2:"h2",header:"header",p:"p",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"what-we-do",children:"What We Do"})}),"\n",(0,i.jsx)(t.h2,{id:"get-started-with-gmi-ai-cloud",children:"Get Started with GMI AI Cloud"}),"\n",(0,i.jsx)(t.p,{children:"GMI AI Cloud is connecting the GPU crossroads of both accessibility and affordability for NVIDIA H100 and H200 Tensor Core GPUs, offering a pivotal connection point for advanced computing resources. Elevate your infrastructure with GMI AI Cloud through access to Bare Metal or Kubernetes-as-a-Service (K8)."}),"\n",(0,i.jsx)(t.h2,{id:"hassle-free-deployment",children:"Hassle Free Deployment"}),"\n",(0,i.jsx)(t.p,{children:"Reduce the time required for docker image preparation. One click to launch specialized containers to perform model training and inference by using docker image library prebuilt by our experts."}),"\n",(0,i.jsx)(t.h2,{id:"cloud-native-orchestration",children:"Cloud-native Orchestration"}),"\n",(0,i.jsx)(t.p,{children:"Deep platform integration with kubernetes, from our control plane to management APIs. Use familiar tooling to easily define and run containerized model training and inference workloads and scale them from one GPU to hundreds."}),"\n",(0,i.jsx)(t.h2,{id:"bare-metal-storagenetworking",children:"Bare-metal Storage/Networking"}),"\n",(0,i.jsx)(t.p,{children:"Decrease complexity by deploying containerized workloads while getting the performance of bare-metal with no hypervisor layer. Remove bottlenecks by provisioning industry-leading storage and networking bandwidth."}),"\n",(0,i.jsx)(t.h2,{id:"flexible-gpu-compute",children:"Flexible GPU Compute"}),"\n",(0,i.jsx)(t.p,{children:"Right-size jobs and provision varied pools of GPU resources for models of all sizes. Take advantage of over 5+ different Nvidia GPU SKUs to optimize your price/performance ratio for both training and inference."}),"\n",(0,i.jsx)(t.h2,{id:"robust-security",children:"Robust Security"}),"\n",(0,i.jsx)(t.p,{children:"Data security is paramount. We offer comprehensive protection features, such as encryption-at-rest and in-transit, multi-factor authentication, and stringent access control mechanisms. Our approach to global compliance maximizes our ability to work even in stringent industries such as telecommunications, healthcare, and research."}),"\n",(0,i.jsx)(t.h2,{id:"unprecedented-hardware-access",children:"Unprecedented Hardware Access"}),"\n",(0,i.jsx)(t.p,{children:"Run your workloads on the latest NVIDIA H100 Tensor Core GPUs, including 8x 80GB multi-card servers with InfiniBand."})]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var r=n(6540);const i={},o=r.createContext(i);function a(e){const t=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(o.Provider,{value:t},e.children)}}}]);