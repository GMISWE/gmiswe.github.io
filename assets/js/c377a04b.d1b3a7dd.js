"use strict";(self.webpackChunkdocument_site=self.webpackChunkdocument_site||[]).push([[3361],{2502:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"index","title":"Welcome to the GMI Cloud Resource Docs!","description":"Whether you\'re deploying AI models, managing GPU clusters, or migrating workloads, this guide will help you navigate our platform with ease. Choose a section below to get started.","source":"@site/docs/index.md","sourceDirName":".","slug":"/","permalink":"/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"hide_table_of_contents":true,"sidebar_label":"Welcome!"},"sidebar":"tutorialSidebar","next":{"title":"What We Do","permalink":"/intro"}}');var i=o(4848),r=o(8453);const s={sidebar_position:1,hide_table_of_contents:!0,sidebar_label:"Welcome!"},a="Welcome to the GMI Cloud Resource Docs!",l={},c=[{value:"Inference Engine",id:"inference-engine",level:2},{value:"Optimization for faster, high-performance inference",id:"optimization-for-faster-high-performance-inference",level:3},{value:"Cluster Engine",id:"cluster-engine",level:2},{value:"Dynamic Resource Management and Orchestration",id:"dynamic-resource-management-and-orchestration",level:3},{value:"Migration Guide",id:"migration-guide",level:2},{value:"Moving AI Workloads to GMI Cloud",id:"moving-ai-workloads-to-gmi-cloud",level:3}];function d(e){const n={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"welcome-to-the-gmi-cloud-resource-docs",children:"Welcome to the GMI Cloud Resource Docs!"})}),"\n",(0,i.jsx)(n.p,{children:"Whether you're deploying AI models, managing GPU clusters, or migrating workloads, this guide will help you navigate our platform with ease. Choose a section below to get started."}),"\n",(0,i.jsx)(n.h2,{id:"inference-engine",children:(0,i.jsx)(n.a,{href:"/inference-engine",children:"Inference Engine"})}),"\n",(0,i.jsx)(n.h3,{id:"optimization-for-faster-high-performance-inference",children:"Optimization for faster, high-performance inference"}),"\n",(0,i.jsx)(n.p,{children:"You\u2019re about to supercharge your AI models with lightning-fast inference. Inference Engine makes it easy to scale, and optimize your models for real-time performance. Let\u2019s get started\u2014your AI is ready to shine."}),"\n",(0,i.jsx)(n.h2,{id:"cluster-engine",children:(0,i.jsx)(n.a,{href:"/cluster-engine",children:"Cluster Engine"})}),"\n",(0,i.jsx)(n.h3,{id:"dynamic-resource-management-and-orchestration",children:"Dynamic Resource Management and Orchestration"}),"\n",(0,i.jsx)(n.p,{children:"You now have full control over your GPU clusters, giving you the flexibility to train, fine-tune, and scale your AI workloads with ease. Cluster Engine simplifies resource management so you can focus on performance and efficiency. Let\u2019s get started."}),"\n",(0,i.jsx)(n.h2,{id:"migration-guide",children:(0,i.jsx)(n.a,{href:"/migration",children:"Migration Guide"})}),"\n",(0,i.jsx)(n.h3,{id:"moving-ai-workloads-to-gmi-cloud",children:"Moving AI Workloads to GMI Cloud"}),"\n",(0,i.jsx)(n.p,{children:"You've made it. Moving to GMI Cloud is the best decision for your AI workloads, and we\u2019re here to make the transition smooth, fast, and stress-free. Follow this guide, and you\u2019ll be up and running in no time. Let\u2019s get you settled into your new AI home."})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>a});var t=o(6540);const i={},r=t.createContext(i);function s(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);